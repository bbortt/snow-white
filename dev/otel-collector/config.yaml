receivers:
  kafka/snow-white:
    brokers:
      - kafka:9094
    protocol_version: 4.0.0
    traces:
      encoding: otlp_json
      # TODO https://github.com/bbortt/snow-white/issues/287
      # encoding: otlp_proto
      topic: snow-white_outbound
  otlp:
    protocols:
      grpc:
        endpoint: '0.0.0.0:4317'
      http:
        endpoint: '0.0.0.0:4318'
        cors:
          allowed_origins:
            - 'http://localhost:*'
processors:
  memory_limiter:
    check_interval: 5s
    limit_percentage: 80
    spike_limit_percentage: 25
  batch:
    send_batch_size: 512
    send_batch_max_size: 1024
  filter/openapi-traces:
    error_mode: ignore
    traces:
      span:
        - attributes["http.request.method"] == nil
        - attributes["api.name"] == nil
        - attributes["api.version"] == nil
  filter/snow-white-microservices:
    error_mode: propagate
    traces:
      span:
        - resource.attributes["service.name"] == "api-gateway"
        - resource.attributes["service.name"] == "api-sync-job"
        - resource.attributes["service.name"] == "otel-event-filter-stream"
        - resource.attributes["service.name"] == "openapi-coverage-stream"
        - resource.attributes["service.name"] == "quality-gate-api"
        - resource.attributes["service.name"] == "report-coordinator-api"
  filter/all-external-services:
    error_mode: propagate
    traces:
      span:
        - |
          resource.attributes["service.name"] != "api-gateway" and
          resource.attributes["service.name"] != "api-sync-job" and
          resource.attributes["service.name"] != "otel-event-filter-stream" and
          resource.attributes["service.name"] != "openapi-coverage-stream" and
          resource.attributes["service.name"] != "quality-gate-api" and
          resource.attributes["service.name"] != "report-coordinator-api"
  groupbyattrs/service:
    keys:
      - service.name
      - service.namespace
      - service.version
  groupbytrace:
    wait_duration: 5s
    num_traces: 512
  resource/cleanup:
    attributes:
      - action: delete
        pattern: ^process\..+
      - action: delete
        pattern: ^telemetry\..+
extensions:
  health_check:
    endpoint: '0.0.0.0:13133'
    check_collector_pipeline:
      enabled: true
      interval: 30s
  zpages: {}
exporters:
  debug/basic:
    verbosity: basic
    sampling_initial: 5
  debug/detailed:
    verbosity: detailed
    sampling_initial: 5
  kafka/snow-white:
    brokers:
      - kafka:9094
    partition_traces_by_id: true
    protocol_version: 4.0.0
    traces:
      encoding: otlp_json
      # TODO https://github.com/bbortt/snow-white/issues/287
      # encoding: otlp_proto
      topic: snow-white_inbound
  influxdb:
    endpoint: http://influxdb:8086
    org: snow-white
    bucket: raw-data
    token: ${INFLUXDB_TOKEN}
  otlp/infra:
    endpoint: 'jaeger:4317'
    tls:
      insecure: true
  prometheus:
    endpoint: '0.0.0.0:8090'
    send_timestamps: true
    metric_expiration: 10m
    enable_open_metrics: true
    resource_to_telemetry_conversion:
      enabled: true
service:
  extensions: [health_check, zpages]
  pipelines:
    logs/infra:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [debug/basic]
    metrics/infra:
      receivers: [otlp]
      processors: [memory_limiter, groupbyattrs/service, batch]
      exporters: [debug/basic]
    traces/snow-white:
      receivers: [otlp]
      processors:
        [
          memory_limiter,
          filter/snow-white-microservices,
          filter/openapi-traces,
          groupbytrace,
          resource/cleanup,
          batch,
        ]
      exporters: [debug/basic, kafka/snow-white]
    traces/influxdb:
      receivers: [kafka/snow-white]
      processors: [memory_limiter, groupbytrace, batch]
      exporters: [debug/basic, influxdb]
    traces/infra:
      receivers: [otlp]
      processors:
        [memory_limiter, filter/all-external-services, groupbytrace, batch]
      exporters: [debug/basic, otlp/infra]
  telemetry:
    logs:
      level: INFO # DEBUG
      sampling:
        initial: 100
    metrics:
      level: detailed
      readers:
        - pull:
            exporter:
              prometheus:
                host: '0.0.0.0'
                port: 8888
